<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>compute on Lei.Chat()</title>
    <link>https://www.lei.chat/tags/compute/</link>
    <description>Recent content in compute on Lei.Chat()</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>&amp;copy; 2018 - 2026 &lt;a href=&#34;https://www.lei.chat/&#34;&gt;Lei Zhang&lt;/a&gt;
</copyright>
    <lastBuildDate>Tue, 31 Dec 2024 14:21:28 -0800</lastBuildDate><atom:link href="https://www.lei.chat/tags/compute/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Triton Linear Layout: Concept</title>
      <link>https://www.lei.chat/posts/triton-linear-layout-concept/</link>
      <pubDate>Tue, 31 Dec 2024 14:21:28 -0800</pubDate>
      
      <guid>https://www.lei.chat/posts/triton-linear-layout-concept/</guid>
      <description>&lt;p&gt;Layout is a core concept in Triton for representing and optimizing distribution
mappings from source problems to the target hardware compute and memory
hierarchy.
In this blog post I will talk about linear layout in Triton, the new unifying
mechanism over existing bespoke layouts for different purposes.
The aim is to provide motivation and an intuitive understanding of linear
layout;
I will rely on examples and illustrations instead of theories and proofs.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Leaving Google</title>
      <link>https://www.lei.chat/posts/leaving-google/</link>
      <pubDate>Tue, 26 Sep 2023 14:50:03 -0700</pubDate>
      
      <guid>https://www.lei.chat/posts/leaving-google/</guid>
      <description>&lt;p&gt;Time flies&amp;mdash;almost 9 years have passed since I joined Google.
Now the time has come for me to leave and move on.
While here, I&amp;rsquo;m super lucky to mostly work on open source projects that I can
publicly talk about.
So at the end of my tenure with Google, I&amp;rsquo;d like to reflect and summarize the
incredible journey, which I am super grateful for and thoroughly enjoyed,
before I forget some details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>GPGPU, ML Inference, and Vulkan Compute</title>
      <link>https://www.lei.chat/posts/gpgpu-ml-inference-and-vulkan-compute/</link>
      <pubDate>Sun, 25 Jul 2021 11:25:26 -0400</pubDate>
      
      <guid>https://www.lei.chat/posts/gpgpu-ml-inference-and-vulkan-compute/</guid>
      <description>&lt;p&gt;Nowadays GPUs are utilized for both graphics rendering and general-purpose
compute (GPGPU). For the latter, CUDA is the indisputable leading solution.
Though, with so many other GPU vendors, the quest for a GPGPU standard never
stops. OpenCL was a great attempt and is used widely; but still it falls
short on many aspects.
Given the success of Vulkan in graphics and it being both a graphics and
compute API, one would wonder whether it can actually be the next-generation
GPGPU standard. I certainly believe so; but the road is not full of roses.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>What is Vulkan Compute?</title>
      <link>https://www.lei.chat/posts/what-is-vulkan-compute/</link>
      <pubDate>Fri, 25 Jun 2021 10:15:58 -0400</pubDate>
      
      <guid>https://www.lei.chat/posts/what-is-vulkan-compute/</guid>
      <description>&lt;p&gt;Vulkan is designed to be both a graphics and compute API. However, there is no
formal definition of the compute subset from the Khronos group, the industry
consortium behind Vulkan. The unified specification of Vulkan does not help here
either as it contains everything, both graphics and compute. Unlike the
complicated graphics subset, the compute subset is actually quite
straightforward and clean. So in this blog post I try to explain what Vulkan
compute is, from my point of view.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
